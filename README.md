# üè• Multimodal Medical AI Diagnostic System
### Integrating 3D Volumetric Segmentation, X-Ray Classification & Biomedical NLP

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)
![Flask](https://img.shields.io/badge/Backend-Flask-green)
![React](https://img.shields.io/badge/Frontend-React-cyan)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ü©∫ About The Project

This project is a comprehensive, **multimodal Clinical Decision Support System (CDSS)** designed to bridge the gap between complex medical imaging and automated diagnosis. Unlike standard single-task models, this framework unifies three distinct AI disciplines‚Äî**3D Computer Vision**, **2D Medical Imaging**, and **Natural Language Processing (NLP)**‚Äîinto a single, deployable pipeline.

The system is engineered to assist radiologists by providing:
1.  **Automated Segmentation** of brain tumors from 3D MRI scans (BraTS).
2.  **Pathology Classification** from 2D Chest X-Rays.
3.  **Semantic Context** extraction from unstructured clinical notes.

## ‚ú® Key Architectures & Features

### üß† 1. Advanced 3D Segmentation (BraTS MRI)
* **Architecture:** Custom **Residual Attention SE 3D U-Net**.
* **Innovation:** Combines **Residual connections** for deep feature propagation, **Squeeze-and-Excitation (SE) blocks** for channel-wise feature recalibration, and **Attention Gates** to suppress background noise.
* **Performance:** Achieves **~0.90 Dice Score** on Whole Tumor (WT) and **0.82** on Tumor Core (TC).
* **Engineering:** Features a custom `float32` memory-safe NIfTI loader and **Automatic Mixed Precision (AMP)** training.

### ü©ª 2. X-Ray Pathology Classification
* **Architecture:** **DenseNet121** (Transfer Learning).
* **Optimization:** Custom classifier head (`Linear` ‚Üí `ReLU` ‚Üí `Dropout` ‚Üí `Sigmoid`) designed to prevent overfitting on small medical datasets.
* **Explainability:** Integrated **Grad-CAM** (Gradient-weighted Class Activation Mapping) to visualize heatmaps, allowing clinicians to verify *where* the model is looking.

### üìù 3. Clinical NLP (BioBERT)
* **Model:** Fine-tuned **BioBERT** (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining).
* **Function:** Parses unstructured medical reports to extract Named Entities (Symptoms, Diseases, Medications) and correlates them with visual findings.


## üèóÔ∏è System Architecture

The platform operates as a unified pipeline where the **Flask Backend** orchestrates three specialized AI engines, serving results to a **React Frontend** for clinical review.



```mermaid
graph TD
    User[Clinician] -->|Uploads Data| Frontend[React Dashboard]
    Frontend -->|REST API| Backend[Flask Server]
    
    subgraph "Deep Learning Core (PyTorch)"
        Backend -->|3D MRI Volume| UNet[Residual Attn SE 3D U-Net]
        Backend -->|Chest X-Ray| DenseNet[DenseNet121 + Grad-CAM]
        Backend -->|Clinical Notes| BioBERT[BioBERT NER]
    end
    
    UNet -->|Segmentation Mask| Backend
    DenseNet -->|Heatmap & Probability| Backend
    BioBERT -->|Extracted Entities| Backend
    
    Backend -->|JSON & Visualization| Frontend

```
### üíª Installation & Setup

Prerequisites
Python 3.8+ (Tested on 3.10)

Node.js & npm (For the frontend interface)

CUDA-enabled GPU (Highly recommended for 3D inference)

1. Clone the Repository
```text
git clone [https://github.com/your-username/medical-ai-platform.git](https://github.com/your-username/medical-ai-platform.git)
cd medical-ai-platform
```

## üöÄ Deployment & DevOps

This project leverages modern **DevOps practices** to ensure reproducibility and scalability. The application is fully containerized using **Docker** and orchestrated via **Docker Compose**, ensuring it runs identically on any machine (local, cloud, or hospital server).

### üê≥ Docker Quick Start
No need to install Python or Node.js manually. Just run:

```bash
# Build and start the entire platform
docker-compose up --build
```

## üß† Model Training & Usage

### 1. Training the 3D U-Net (Segmentation)
To train the Residual Attention SE 3D U-Net from scratch using the BraTS dataset:

```bash
# Trains for 50 epochs with Mixed Precision (AMP)
# Automatically saves 'best_model.pth' when validation Dice improves
python -m backend.src.segmentation.train

```

2. Evaluating Performance
To run the rigorous evaluation pipeline (calculating Dice scores per class and generating "Worst Case" error analysis):

```bash
python -m backend.src.segmentation.evaluate
```

3. Running the Web Platform
To launch the full interactive diagnostic system:

```bash 
# Terminal 1: Start the Flask Backend (API)
cd backend
python app.py

# Terminal 2: Start the React Frontend (UI)
cd frontend
npm start

```

## üìÇ Project Structure

The project follows a modular "Microservices-like" architecture, separating the Deep Learning Core from the Web Interface.

```text
Medical-AI-Project/
‚îú‚îÄ‚îÄ backend/                  # Flask API & Deep Learning Core
‚îÇ   ‚îú‚îÄ‚îÄ app.py                # Main API Entrypoint
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile            # Backend Container Config
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ segmentation/     # 3D U-Net Logic (BraTS)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unet_3d.py    # Custom Residual Attention SE Architecture
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py      # Mixed Precision Training Loop
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py   # Worst-Case Error Analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diagnosis/ 
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nlp/              # BioBERT Clinical Note Parser
‚îÇ   ‚îî‚îÄ‚îÄ data/                 # Raw & Processed Medical Data
‚îÇ
‚îú‚îÄ‚îÄ frontend/                 # React Dashboard
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/       # Reusable UI Elements (Upload, Viewer)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.js            # Main Frontend Logic
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile            # Frontend Container Config
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml        # Orchestration for Full Stack Deployment
‚îî‚îÄ‚îÄ .github/workflows/        # CI/CD Pipeline (GitHub Actions)

```
## Explaining the custom 3D U-Net

### üß¨ Data Augmentation Pipeline (Augment3D)

To combat overfitting‚Äîa common challenge in medical deep learning due to limited datasets‚Äîwe implemented a robust, on-the-fly 3D augmentation pipeline. The Augment3D class applies stochastic transformations to every batch during training, effectively generating infinite variations of the training data.

The pipeline is divided into two distinct categories:

**1. Consistent Spatial Transformations (Geometric)**
Applied simultaneously to both the MRI volume (x) and the Ground Truth mask (y) to maintain anatomical alignment.
. **Random Flip**: Stochastically mirrors the volume along the Height or Width axes ($p=0.5$).
. **Random 90¬∞ Rotation**: Performs rigid rotations (90¬∞, 180¬∞, or 270¬∞) in the axial plane. Unlike interpolation-based rotations, ```text np.rot90``` preserves exact voxel values without introducing aliasing artifacts.

**2. Diverse Intensity Transformations (Photometric)**
Applied only to the MRI volume ($x$) to simulate scanner variability and artifacts, forcing the model to learn structural features rather than relying on absolute pixel intensities.

**Gaussian Noise**: Injects random grain ($p=0.2$) to simulate sensor noise inherent in MRI acquisition.
**Bias & Contrast Shifting**: Randomly adjusts global brightness (Bias) and scales pixel value ranges (Contrast) to handle varying scanner calibrations.
**Gamma Correction**: Applies non-linear power-law transformations ($x^{\gamma}$) to simulate different contrast settings (e.g., darker or lighter tissue appearance).
**Gaussian Blur**: Softens edges ($p=0.2$) using ```text scipy.ndimage```, mimicking motion blur or lower-resolution scans.

**Technical Implementation**: The pipeline ensures memory safety by explicitly handling negative strides (via ```text .copy()```) and casting data to float32 to prevent numerical instability during mathematical operations.

### üß† Deep Learning Architecture: Residual Attention SE 3D U-Net

I architected a custom, high-fidelity 3D U-Net designed specifically to handle the volumetric complexity and class imbalance inherent in BraTS MRI data.
The architecture integrates three state-of-the-art mechanisms into a unified pipeline:

1. The Backbone: 3D Residual Encoder-Decoder

Unlike standard 2D approaches that process MRI slices individually (losing Z-axis context), our network operates on full 4D tensors $(C, D, H, W)$.

Residual Connections: Inspired by ResNet, we replaced standard convolutional blocks with Residual Units.

Why? In deep 3D networks, gradients often vanish during backpropagation. Residual skips allow gradients to flow through the network unimpeded, enabling deeper feature extraction without degradation.

## üß† Technical Implementation Details

The core of our segmentation framework is a custom `UNet3D` class defined in `backend/src/segmentation/unet_3d.py`. This section details the component-level logic from weight initialization to the final layer assembly.

### 1. Robust Initialization Strategy (`_init_weights`)
Deep 3D networks are highly susceptible to the **Vanishing Gradient** problem. To ensure signal propagation through 50+ layers, we implement a custom initialization scheme rather than relying on PyTorch defaults.

* **Convolutional Layers:** We use **Kaiming (He) Normal Initialization** (`mode='fan_out'`).
    * *Code:* `nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')`
    * *Why:* This preserves the variance of the forward pass, preventing activation collapse in the early epochs of training 3D volumes.
* **Normalization Layers:** InstanceNorm weights are initialized to 1 and bias to 0 to start as identity transformations.

### 2. The "Holy Trinity" Building Blocks

Our architecture creates a "Super-Block" by combining three distinct mechanisms:

#### A. Squeeze-and-Excitation (SE) Block

Located inside every residual unit, this block performs **dynamic channel recalibration**.
* **Squeeze:** `nn.AdaptiveAvgPool3d(1)` compresses the 3D spatial dimensions $(D, H, W)$ into a global channel descriptor $(C, 1, 1, 1)$.
* **Excitation:** A bottleneck MLP reduces complexity by ratio $r=8$ (`Linear` $\to$ `ReLU` $\to$ `Linear` $\to$ `Sigmoid`).
* **Impact:** It learns a weight vector $\sigma$ that amplifies tumor-relevant channels while suppressing noise channels before they enter the next layer.

#### B. Residual SE Block (The Encoder Unit)
We replace standard convolutions with a Residual structure to facilitate deep learning.
* **Structure:** `Input` + `Residual(Input)`
* **Path:** `Conv3D` $\to$ `InstanceNorm` $\to$ `LeakyReLU` $\to$ `Conv3D` $\to$ `InstanceNorm` $\to$ **`SEBlock`** $\to$ `Dropout`.
* **Logic:** The residual connection `x + residual` allows gradients to flow directly through the network during backpropagation, solving the degradation problem.

#### C. Attention Gates (The Decoder Unit)

Located at the skip connections, these gates filter the feature maps coming from the Encoder.
* **Inputs:**
    * $x$: High-res features from the Encoder (noisy).
    * $g$: Contextual features from the deeper Decoder layer.
* **Mechanism:** The gate computes an alignment map via `Sigmoid(W_x(x) + W_g(g))`.
* **Result:** This map acts as a "soft mask" (0 to 1), effectively zeroing out background regions in the skip connection so the decoder only processes relevant anatomical features.

### 3. Macro-Architecture (The 3D U-Net)

The model follows a symmetric Encoder-Decoder structure with mathematically aligned channel expansions.

| Stage | Unit Type | Input Channels | Output Channels | Feature Map |
| :--- | :--- | :--- | :--- | :--- |
| **Encoder 1** | Residual SE | 4 | 16 | $128^3$ |
| **Encoder 2** | Residual SE | 16 | 32 | $64^3$ |
| **Encoder 3** | Residual SE | 32 | 64 | $32^3$ |
| **Bottleneck** | Residual SE | 128 | 256 | $8^3$ |
| **Decoder 4** | Attn Gate + Up | 256 + 128 | 128 | $16^3$ |
| **Decoder 3** | Attn Gate + Up | 128 + 64 | 64 | $32^3$ |
| **Output** | Conv3D (1x1) | 16 | 3 (WT, TC, ET) | $128^3$ |

*Note: We utilize `trilinear` interpolation for upsampling to preserve smooth 3D spatial coherence.*

## ‚öôÔ∏è Advanced Training Methodology

To maximize the performance of the Residual Attention SE 3D U-Net, we implemented a rigorous training pipeline designed to handle the specific challenges of medical volumetry: class imbalance, memory constraints, and convergence instability.

### 1. Hybrid Loss Function (The "Best of Both Worlds")
Training on Dice Score alone can be unstable due to its non-convex nature. Training on Cross-Entropy alone often ignores global geometry.
We utilized a **Compound Loss Function** combining the pixel-wise precision of Binary Cross Entropy (BCE) with the global overlap optimization of Soft Dice Loss.

$$\mathcal{L}_{total} = \mathcal{L}_{BCE}(y, \hat{y}) + \mathcal{L}_{Dice}(y, \hat{y})$$

* **BCE Component:** Stabilizes gradients early in training by penalizing pixel-level classification errors.
* **Soft Dice Component:** Directly optimizes the evaluation metric (IOU), handling the severe class imbalance (small tumor vs. large background) without needing manual class weighting.

### 2. Automatic Mixed Precision (AMP) ‚ö°
3D MRI volumes are memory-intensive. Training a 50-layer 3D network on standard GPUs is often impossible with `float32` precision.
* **Implementation:** We leveraged `torch.amp.autocast` (PyTorch 2.6+) to dynamically switch between `float16` (half precision) for matrix multiplications and `float32` (single precision) for accumulation.
* **GradScaler:** A gradient scaler was implemented to prevent "underflow" (gradients becoming so small they round to zero) common in `float16` backpropagation.
* **Result:** Reduced VRAM usage by ~40% and increased training speed by 2x, allowing for larger batch sizes and deeper network layers.

### 3. Optimization Strategy
* **Optimizer:** **AdamW** (Adam with Weight Decay `1e-5`). Unlike standard Adam, AdamW decouples weight decay from gradient updates, leading to better generalization on medical data.
* **Learning Rate Scheduler:** We employed a **ReduceLROnPlateau** scheduler.
    * *Mechanism:* Monitors the Validation Dice Score.
    * *Trigger:* If performance stagnates for **5 epochs** (patience), the Learning Rate is reduced by a factor of **0.5**.
    * *Impact:* This allows the model to make coarse adjustments early on and fine-tune weights with high precision towards the end of training (the "fine-tuning phase").

### 4. "Leakage-Proof" Data Pipeline
To ensure research integrity, we strictly separated **Data Augmentation** from **Data Loading**:
1.  **Physical Split:** Files are physically moved to `train/` and `test/` directories before training begins.
2.  **On-the-Fly Augmentation:** Geometric and intensity transforms are applied in RAM only during the `__getitem__` call.
3.  **Result:** Guarantees mathematically zero data leakage between training samples and validation metrics.


## üìä Experimental Results & Performance Analysis

### 1. Dataset & Methodology
To ensure rigorous evaluation, we utilized the **BraTS 2021** dataset. Since the official test set labels are withheld by the challenge organizers (evaluation server), we implemented a strict **80/20 Hold-Out Split** on the provided training data:
* **Training Set (80%):** 295 patients used for optimization.
* **Test Set (20%):** 74 patients completely unseen during training, used exclusively for the final performance report.

This ensures that the metrics below represent true **generalization capability** and not memorization.

### 2. Quantitative Metrics (Test Set)
After 50 epochs of training, the model achieved peak convergence at **Epoch 39** (Loss=0.1985). The final evaluation on the isolated Test Set yielded the following results:

| Target Structure | Mean Dice Score | Std Dev | Clinical Significance |
| :--- | :--- | :--- | :--- |
| **Whole Tumor (WT)** | **0.8961** | ¬±0.09 | Excellent boundary detection for the complete abnormality (Edema + Core). |
| **Tumor Core (TC)** | **0.8227** | ¬±0.18 | **SOTA-Level Performance.** Critically high precision in separating the necrotic core from edema. |
| **Enhancing Tumor (ET)**| **0.7409** | ¬±0.25 | Strong detection of active tumor regions, despite high variance in small lesions. |

> **Note on Tumor Core (TC):** A Dice score >0.80 on the Tumor Core is traditionally the hardest benchmark in BraTS. Our **Residual Attention SE** architecture specifically excelled here, peaking at **0.8860** on the internal validation set during training.


### üìä Benchmarking vs. State-of-the-Art (nnU-Net)

To evaluate both performance and stability, we compared our segmentation results against **nnU-Net**, the winner of the BraTS 2020 challenge.

Our model demonstrates **superior stability** (lower standard deviation) in delineating the Whole Tumor and Tumor Core, indicating more consistent performance across diverse patient scans.

| Tumor Region | Our Model (Dice Score) | nnU-Net (Dice Score) | Stability (Std Dev) |
| :--- | :---: | :---: | :--- |
| **Whole Tumor (WT)** | **89.48 ¬± 9.32** | 88.95 ¬± 13.23 | ‚úÖ **+30% More Stable** |
| **Tumor Core (TC)** | 81.28 ¬± 19.89 | 85.06 ¬± 24.02 | ‚úÖ **+17% More Stable** |
| **Enhancing Tumor (ET)** | 74.10 ¬± 25.71 | 82.03 ¬± 19.71 | High Variance |

> **Key Insight:** While nnU-Net achieves higher peak scores in some sub-regions, our architecture yields a **lower standard deviation for WT and TC**, suggesting a more robust and predictable model for clinical deployment.

> **Methodology:**
> * **Our Results:** Evaluation on a **20% hold-out test set** split from the official BraTS training data.
> * **nnU-Net Results:** Benchmarks sourced from the [BraTS 2020 Challenge Rankings](https://www.med.upenn.edu/cbica/brats2020/rankings.html).



### 3. Error Analysis & Robustness
We went beyond average metrics to analyze specific failure modes:

* **üèÜ Best Case (Patient #28):** Achieved a near-perfect **Dice of 0.9765**. The model captured complex, irregular tumor shapes with human-level accuracy.
* **üìâ Worst Case (Patient #52):** Recorded a Dice of **0.3444**.
    * *Root Cause Analysis:* Visual inspection reveals Patient #52 contains micro-lesions (<5mm) with low contrast in the T1ce modality. This highlights a known limitation of CNNs on sub-voxel targets and suggests a path for future improvement via **Deep Supervision**.



### Visual Results
The model provides high-precision segmentation of clinical regions of interest. Below is an example of the best-performing case:

![Segmentation Best Case](https://raw.githubusercontent.com/Iyed0092/Multimodal-Clinical-Decision-Support-System/main/segmentation_best_case.png)



### 4. Convergence Profile
The training process demonstrated stable convergence, with the **Hybrid Loss** (BCE + Dice) effectively preventing oscillation.

* **Initial Loss:** 0.5314 (Epoch 1)
* **Final Loss:** 0.1985 (Epoch 39)
* **Impact:** The steady decline in loss coupled with the rise in TC Dice (from 0.71 to 0.88) validates the effectiveness of the **Squeeze-and-Excitation blocks** in learning discriminative features over time.



---

## ü©ª 2D X-Ray Pathology Classification Module

While 3D MRI handles complex volumetric segmentation, the 2D X-Ray module is designed for rapid, automated screening of common thoracic pathologies (e.g., Pneumonia).

### 1. Model Architecture: Transfer Learning with DenseNet121
We leverage **Transfer Learning**, initializing our model with weights pre-trained on ImageNet to extract robust low-level visual features (edges, textures).

* **Why DenseNet121?** Unlike traditional CNNs (like ResNet), DenseNet connects every layer to every subsequent layer in a feed-forward fashion.
* **Medical Advantage:** This dense connectivity promotes strong **feature reuse** and mitigates the vanishing gradient problem. For medical datasets, which are often smaller than natural image datasets, this architecture is highly efficient at maximizing information flow from limited samples.

### 2. Technical Innovation: Custom Regularized Classifier Head
A naive transfer learning approach (just swapping the last layer) often leads to severe overfitting on medical data. We engineered a custom classification "top" specifically for robust binary diagnosis.

The original 1000-class ImageNet head was replaced with:

```mermaid
graph TD
    Features[DenseNet Features: 1024] --> pooling[Adaptive Avg Pool]
    pooling --> flat[Flatten]
    flat --> fc1[Linear: 1024 ‚Üí 512]
    fc1 --> relu[ReLU Activation]
    relu --> drop[Dropout: p=0.5]
    drop --> fc2[Linear: 512 ‚Üí 1]
    fc2 --> sigmoid[Sigmoid Output]
    sigmoid --> prob[Probability Score: 0-1]

    %% Styling for a professional look
    style Features fill:#f0f4f8,stroke:#334e68,stroke-width:2px
    style drop fill:#fff0f6,stroke:#a61e4d,stroke-width:1px,stroke-dasharray: 5 5
    style prob fill:#ebfbee,stroke:#2b8a3e,stroke-width:2px
```

**Bottleneck Layer:** Compresses high-dimensional features to a dense 512-vector representation.

**Aggressive Dropout (p=0.5)**: The key constraint. During training, 50% of neurons are randomly zeroed out. This forces the network to learn redundant, robust representations of pathology rather than memorizing specific training examples.

**3. Explainable AI (XAI): Grad-CAM Integration**

In clinical practice, a high accuracy score is insufficient without justification. Doctors need to trust why the model made a decision.

We integrated Grad-CAM (Gradient-weighted Class Activation Mapping) into the inference pipeline.

**Mechanism**: Grad-CAM computes the gradients of the predicted class score (e.g., "Pneumonia") with respect to the feature maps of the final convolutional layer of the DenseNet backbone.

**Result**: These gradients act as weights to generate a coarse heat-map, highlighting the regions in the X-Ray that most heavily influenced the positive prediction.

**Clinical Utility**: It allows radiologists to verify if the model is focusing on relevant anatomical anomalies (e.g., lung opacities) rather than confounding artifacts (e.g., medical devices or bone structures).



---

## üìù 3. Clinical NLP & Semantic Analysis Module

Medical diagnosis rarely relies on imaging alone. To provide a holistic patient profile, we integrated a **Natural Language Processing (NLP)** engine capable of parsing unstructured clinical notes and extracting actionable insights.

### 1. Architecture: Domain-Specific Transformers
Standard NLP models (like BERT) fail on medical jargon. We utilized **BioBERT** (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), a model pre-trained on massive biomedical corpora (PubMed, PMC) to understand clinical terminology.

The module (`backend/src/nlp/clinical_nlp.py`) implements two distinct pipelines using the Hugging Face ecosystem:


```mermaid
graph TD
    Patient(Patient Arrives) -->|Symptom: Chest Pain| Triage[Hospital Triage]
    Triage -->|Acquire Image| XRay[X-Ray Scan]
    XRay -->|DICOM Data| AI[AI Diagnostic Model]
    
    subgraph AI_Analysis [AI Decision Process]
        AI -->|Forward Pass| Class[Classification: Pneumonia]
        AI -->|Grad-CAM| Heatmap[Visual Heatmap]
    end

    Class --> Doctor{Radiologist Review}
    Heatmap --> Doctor
    
    Doctor -->|Confirm| Treat[Treatment Plan]
    Doctor -->|Reject| Retest[Further Testing]

    %% Styles for clinical look
    style Patient fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    style AI_Analysis fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,stroke-dasharray: 5 5
    style Doctor fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
```

**2. Capabilities & Implementation**

**A. Biomedical Named Entity Recognition (NER)**
We deploy the d4data/biomedical-ner-all model to automatically structure free-text notes into categorized entities.

**Aggregation Strategy:** We use "simple" aggregation to merge sub-word tokens (e.g., "hy per ten sion") into single coherent entities ("Hypertension").

**Confidence Filtering:** A strict threshold (score > 0.6) is applied to filter out low-confidence predictions, ensuring only high-probability clinical terms are presented to the user.

**B. Context-Aware Question Answering (Q&A)**
We integrated dmis-lab/biobert-base-cased-v1.1-squad to allow clinicians to interactively query patient records.

**Function:** The model takes a context (the full patient history) and a natural language question (e.g., "What is the prescribed dosage?").

**Extraction:** Instead of generating text (which risks hallucinations), the model extracts the exact span from the source text that answers the question, ensuring factuality.

### üíª Usage Example

```bash
# Real-world inference example
nlp = ClinicalNLP()
note = "Patient presents with severe chest pain. History of hypertension. Prescribed Aspirin 100mg."

# 1. Entity Extraction
entities = nlp.extract_entities(note)
# Output: [{'text': 'chest pain', 'label': 'Symptom'}, {'text': 'Aspirin', 'label': 'Medication'}]

# 2. Interactive Q&A
answer = nlp.answer_question(note, "What medication is the patient on?")
# Output: "Aspirin 100mg" (Score: 0.98)
```
